{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SAT  female  athlete  COLGPA  Unnamed: 4  Unnamed: 5  \\\n",
      "0      920       1        1    2.04         NaN         NaN   \n",
      "1     1170       0        0    4.00         NaN         NaN   \n",
      "2      810       0        1    1.78         NaN         NaN   \n",
      "3      940       0        0    2.42         NaN         NaN   \n",
      "4     1180       0        0    2.61         NaN         NaN   \n",
      "5      980       1        0    3.03         NaN         NaN   \n",
      "6      880       0        0    1.84         NaN         NaN   \n",
      "7      980       0        0    3.05         NaN         NaN   \n",
      "8     1240       0        0    3.00         NaN         NaN   \n",
      "9     1230       0        0    2.00         NaN         NaN   \n",
      "10    1140       1        0    2.98         NaN         NaN   \n",
      "11    1150       1        0    2.93         NaN         NaN   \n",
      "12    1080       0        1    2.00         NaN         NaN   \n",
      "13     990       1        0    2.21         NaN         NaN   \n",
      "14    1000       1        0    3.33         NaN         NaN   \n",
      "15    1050       1        0    1.07         NaN         NaN   \n",
      "16    1160       1        0    2.29         NaN         NaN   \n",
      "17    1190       0        0    3.15         NaN         NaN   \n",
      "18    1030       1        0    2.65         NaN         NaN   \n",
      "19     960       0        1    2.41         NaN         NaN   \n",
      "20     840       0        0    2.39         NaN         NaN   \n",
      "21     920       1        0    2.64         NaN         NaN   \n",
      "22     840       1        0    2.18         NaN         NaN   \n",
      "23    1000       0        0    2.84         NaN         NaN   \n",
      "24    1150       1        0    2.84         NaN         NaN   \n",
      "25    1040       0        0    2.93         NaN         NaN   \n",
      "26     970       1        0    2.29         NaN         NaN   \n",
      "27    1200       1        0    2.38         NaN         NaN   \n",
      "28    1090       1        0    3.92         NaN         NaN   \n",
      "29    1340       0        0    2.23         NaN         NaN   \n",
      "...    ...     ...      ...     ...         ...         ...   \n",
      "3080   820       1        0    1.86         NaN         NaN   \n",
      "3081   940       1        0    1.66         NaN         NaN   \n",
      "3082  1020       0        0    2.80         NaN         NaN   \n",
      "3083  1070       1        0    2.42         NaN         NaN   \n",
      "3084  1130       0        0    2.51         NaN         NaN   \n",
      "3085   820       0        0    1.72         NaN         NaN   \n",
      "3086   880       0        0    0.53         NaN         NaN   \n",
      "3087   850       1        0    0.58         NaN         NaN   \n",
      "3088   840       0        0    2.02         NaN         NaN   \n",
      "3089   790       1        0    2.07         NaN         NaN   \n",
      "3090  1110       1        0    2.47         NaN         NaN   \n",
      "3091  1070       0        0    2.75         NaN         NaN   \n",
      "3092  1020       0        0    2.43         NaN         NaN   \n",
      "3093  1080       0        0    2.43         NaN         NaN   \n",
      "3094   750       0        0    0.66         NaN         NaN   \n",
      "3095   920       1        0    3.30         NaN         NaN   \n",
      "3096   940       0        0    2.15         NaN         NaN   \n",
      "3097   920       1        0    3.29         NaN         NaN   \n",
      "3098  1030       1        0    2.75         NaN         NaN   \n",
      "3099   810       1        0    3.00         NaN         NaN   \n",
      "3100  1110       0        0    3.41         NaN         NaN   \n",
      "3101   950       0        0    1.39         NaN         NaN   \n",
      "3102  1260       0        0    3.75         NaN         NaN   \n",
      "3103   870       1        0    2.84         NaN         NaN   \n",
      "3104  1020       1        0    3.61         NaN         NaN   \n",
      "3105   860       1        0    2.00         NaN         NaN   \n",
      "3106  1150       0        0    2.86         NaN         NaN   \n",
      "3107   860       0        1    2.70         NaN         NaN   \n",
      "3108   820       0        0    1.65         NaN         NaN   \n",
      "3109   890       0        0    2.77         NaN         NaN   \n",
      "\n",
      "                 Unnamed: 6    Unnamed: 7      Unnamed: 8 Unnamed: 9  \\\n",
      "0                       NaN           NaN             NaN        NaN   \n",
      "1                       NaN           NaN             NaN        NaN   \n",
      "2                       NaN           NaN             NaN        NaN   \n",
      "3                       NaN           NaN             NaN        NaN   \n",
      "4                       NaN           NaN             NaN        NaN   \n",
      "5                       NaN           NaN             NaN        NaN   \n",
      "6            SUMMARY OUTPUT           NaN             NaN        NaN   \n",
      "7                       NaN           NaN             NaN        NaN   \n",
      "8     Regression Statistics           NaN             NaN        NaN   \n",
      "9                Multiple R      0.441606             NaN        NaN   \n",
      "10                 R Square      0.195016             NaN        NaN   \n",
      "11        Adjusted R Square      0.194239             NaN        NaN   \n",
      "12           Standard Error      0.584088             NaN        NaN   \n",
      "13             Observations          3110             NaN        NaN   \n",
      "14                      NaN           NaN             NaN        NaN   \n",
      "15                    ANOVA           NaN             NaN        NaN   \n",
      "16                      NaN            df              SS         MS   \n",
      "17               Regression             3         256.709    85.5696   \n",
      "18                 Residual          3106         1059.64   0.341158   \n",
      "19                    Total          3109         1316.35        NaN   \n",
      "20                      NaN           NaN             NaN        NaN   \n",
      "21                      NaN  Coefficients  Standard Error     t Stat   \n",
      "22                Intercept       0.45808       0.0840842    5.44787   \n",
      "23                      SAT    0.00204559     7.80699e-05     26.202   \n",
      "24                   female      0.213985        0.021527    9.94033   \n",
      "25                  athlete     0.0213487       0.0483718   0.441346   \n",
      "26                      NaN           NaN             NaN        NaN   \n",
      "27                      NaN           NaN             NaN        NaN   \n",
      "28                      NaN           NaN             NaN        NaN   \n",
      "29                      NaN           NaN             NaN        NaN   \n",
      "...                     ...           ...             ...        ...   \n",
      "3080                    NaN           NaN             NaN        NaN   \n",
      "3081                    NaN           NaN             NaN        NaN   \n",
      "3082                    NaN           NaN             NaN        NaN   \n",
      "3083                    NaN           NaN             NaN        NaN   \n",
      "3084                    NaN           NaN             NaN        NaN   \n",
      "3085                    NaN           NaN             NaN        NaN   \n",
      "3086                    NaN           NaN             NaN        NaN   \n",
      "3087                    NaN           NaN             NaN        NaN   \n",
      "3088                    NaN           NaN             NaN        NaN   \n",
      "3089                    NaN           NaN             NaN        NaN   \n",
      "3090                    NaN           NaN             NaN        NaN   \n",
      "3091                    NaN           NaN             NaN        NaN   \n",
      "3092                    NaN           NaN             NaN        NaN   \n",
      "3093                    NaN           NaN             NaN        NaN   \n",
      "3094                    NaN           NaN             NaN        NaN   \n",
      "3095                    NaN           NaN             NaN        NaN   \n",
      "3096                    NaN           NaN             NaN        NaN   \n",
      "3097                    NaN           NaN             NaN        NaN   \n",
      "3098                    NaN           NaN             NaN        NaN   \n",
      "3099                    NaN           NaN             NaN        NaN   \n",
      "3100                    NaN           NaN             NaN        NaN   \n",
      "3101                    NaN           NaN             NaN        NaN   \n",
      "3102                    NaN           NaN             NaN        NaN   \n",
      "3103                    NaN           NaN             NaN        NaN   \n",
      "3104                    NaN           NaN             NaN        NaN   \n",
      "3105                    NaN           NaN             NaN        NaN   \n",
      "3106                    NaN           NaN             NaN        NaN   \n",
      "3107                    NaN           NaN             NaN        NaN   \n",
      "3108                    NaN           NaN             NaN        NaN   \n",
      "3109                    NaN           NaN             NaN        NaN   \n",
      "\n",
      "       Unnamed: 10     Unnamed: 11 Unnamed: 12  Unnamed: 13  Unnamed: 14  \n",
      "0              NaN             NaN         NaN          NaN          NaN  \n",
      "1              NaN             NaN         NaN          NaN          NaN  \n",
      "2              NaN             NaN         NaN          NaN          NaN  \n",
      "3              NaN             NaN         NaN          NaN          NaN  \n",
      "4              NaN             NaN         NaN          NaN          NaN  \n",
      "5              NaN             NaN         NaN          NaN          NaN  \n",
      "6              NaN             NaN         NaN          NaN          NaN  \n",
      "7              NaN             NaN         NaN          NaN          NaN  \n",
      "8              NaN             NaN         NaN          NaN          NaN  \n",
      "9              NaN             NaN         NaN          NaN          NaN  \n",
      "10             NaN             NaN         NaN          NaN          NaN  \n",
      "11             NaN             NaN         NaN          NaN          NaN  \n",
      "12             NaN             NaN         NaN          NaN          NaN  \n",
      "13             NaN             NaN         NaN          NaN          NaN  \n",
      "14             NaN             NaN         NaN          NaN          NaN  \n",
      "15             NaN             NaN         NaN          NaN          NaN  \n",
      "16               F  Significance F         NaN          NaN          NaN  \n",
      "17         250.821    9.57641e-146         NaN          NaN          NaN  \n",
      "18             NaN             NaN         NaN          NaN          NaN  \n",
      "19             NaN             NaN         NaN          NaN          NaN  \n",
      "20             NaN             NaN         NaN          NaN          NaN  \n",
      "21         P-value       Lower 95%   Upper 95%  Lower 95.0%  Upper 95.0%  \n",
      "22      5.4955e-08        0.293213    0.622946     0.293213     0.622946  \n",
      "23    6.84933e-137      0.00189252  0.00219866   0.00189252   0.00219866  \n",
      "24     6.09357e-23        0.171777    0.256194     0.171777     0.256194  \n",
      "25        0.658993      -0.0734952    0.116193   -0.0734952     0.116193  \n",
      "26             NaN             NaN         NaN          NaN          NaN  \n",
      "27             NaN             NaN         NaN          NaN          NaN  \n",
      "28             NaN             NaN         NaN          NaN          NaN  \n",
      "29             NaN             NaN         NaN          NaN          NaN  \n",
      "...            ...             ...         ...          ...          ...  \n",
      "3080           NaN             NaN         NaN          NaN          NaN  \n",
      "3081           NaN             NaN         NaN          NaN          NaN  \n",
      "3082           NaN             NaN         NaN          NaN          NaN  \n",
      "3083           NaN             NaN         NaN          NaN          NaN  \n",
      "3084           NaN             NaN         NaN          NaN          NaN  \n",
      "3085           NaN             NaN         NaN          NaN          NaN  \n",
      "3086           NaN             NaN         NaN          NaN          NaN  \n",
      "3087           NaN             NaN         NaN          NaN          NaN  \n",
      "3088           NaN             NaN         NaN          NaN          NaN  \n",
      "3089           NaN             NaN         NaN          NaN          NaN  \n",
      "3090           NaN             NaN         NaN          NaN          NaN  \n",
      "3091           NaN             NaN         NaN          NaN          NaN  \n",
      "3092           NaN             NaN         NaN          NaN          NaN  \n",
      "3093           NaN             NaN         NaN          NaN          NaN  \n",
      "3094           NaN             NaN         NaN          NaN          NaN  \n",
      "3095           NaN             NaN         NaN          NaN          NaN  \n",
      "3096           NaN             NaN         NaN          NaN          NaN  \n",
      "3097           NaN             NaN         NaN          NaN          NaN  \n",
      "3098           NaN             NaN         NaN          NaN          NaN  \n",
      "3099           NaN             NaN         NaN          NaN          NaN  \n",
      "3100           NaN             NaN         NaN          NaN          NaN  \n",
      "3101           NaN             NaN         NaN          NaN          NaN  \n",
      "3102           NaN             NaN         NaN          NaN          NaN  \n",
      "3103           NaN             NaN         NaN          NaN          NaN  \n",
      "3104           NaN             NaN         NaN          NaN          NaN  \n",
      "3105           NaN             NaN         NaN          NaN          NaN  \n",
      "3106           NaN             NaN         NaN          NaN          NaN  \n",
      "3107           NaN             NaN         NaN          NaN          NaN  \n",
      "3108           NaN             NaN         NaN          NaN          NaN  \n",
      "3109           NaN             NaN         NaN          NaN          NaN  \n",
      "\n",
      "[3110 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model    \n",
    "import statsmodels.api as sm  \n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "mydata = pd.read_excel('/Users/ryan/Google Drive/Tulane/Job Stuff/Portfolio Projects/SAT-and-College-GPA/data for jan 27th.xlsx',sheet_name = 'my_data')\n",
    "print(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SAT\n",
      "0      920\n",
      "1     1170\n",
      "2      810\n",
      "3      940\n",
      "4     1180\n",
      "5      980\n",
      "6      880\n",
      "7      980\n",
      "8     1240\n",
      "9     1230\n",
      "10    1140\n",
      "11    1150\n",
      "12    1080\n",
      "13     990\n",
      "14    1000\n",
      "15    1050\n",
      "16    1160\n",
      "17    1190\n",
      "18    1030\n",
      "19     960\n",
      "20     840\n",
      "21     920\n",
      "22     840\n",
      "23    1000\n",
      "24    1150\n",
      "25    1040\n",
      "26     970\n",
      "27    1200\n",
      "28    1090\n",
      "29    1340\n",
      "...    ...\n",
      "3080   820\n",
      "3081   940\n",
      "3082  1020\n",
      "3083  1070\n",
      "3084  1130\n",
      "3085   820\n",
      "3086   880\n",
      "3087   850\n",
      "3088   840\n",
      "3089   790\n",
      "3090  1110\n",
      "3091  1070\n",
      "3092  1020\n",
      "3093  1080\n",
      "3094   750\n",
      "3095   920\n",
      "3096   940\n",
      "3097   920\n",
      "3098  1030\n",
      "3099   810\n",
      "3100  1110\n",
      "3101   950\n",
      "3102  1260\n",
      "3103   870\n",
      "3104  1020\n",
      "3105   860\n",
      "3106  1150\n",
      "3107   860\n",
      "3108   820\n",
      "3109   890\n",
      "\n",
      "[3110 rows x 1 columns]\n",
      "0       2.04\n",
      "1       4.00\n",
      "2       1.78\n",
      "3       2.42\n",
      "4       2.61\n",
      "5       3.03\n",
      "6       1.84\n",
      "7       3.05\n",
      "8       3.00\n",
      "9       2.00\n",
      "10      2.98\n",
      "11      2.93\n",
      "12      2.00\n",
      "13      2.21\n",
      "14      3.33\n",
      "15      1.07\n",
      "16      2.29\n",
      "17      3.15\n",
      "18      2.65\n",
      "19      2.41\n",
      "20      2.39\n",
      "21      2.64\n",
      "22      2.18\n",
      "23      2.84\n",
      "24      2.84\n",
      "25      2.93\n",
      "26      2.29\n",
      "27      2.38\n",
      "28      3.92\n",
      "29      2.23\n",
      "        ... \n",
      "3080    1.86\n",
      "3081    1.66\n",
      "3082    2.80\n",
      "3083    2.42\n",
      "3084    2.51\n",
      "3085    1.72\n",
      "3086    0.53\n",
      "3087    0.58\n",
      "3088    2.02\n",
      "3089    2.07\n",
      "3090    2.47\n",
      "3091    2.75\n",
      "3092    2.43\n",
      "3093    2.43\n",
      "3094    0.66\n",
      "3095    3.30\n",
      "3096    2.15\n",
      "3097    3.29\n",
      "3098    2.75\n",
      "3099    3.00\n",
      "3100    3.41\n",
      "3101    1.39\n",
      "3102    3.75\n",
      "3103    2.84\n",
      "3104    3.61\n",
      "3105    2.00\n",
      "3106    2.86\n",
      "3107    2.70\n",
      "3108    1.65\n",
      "3109    2.77\n",
      "Name: COLGPA, Length: 3110, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(mydata,columns=['SAT', 'COLGPA'])    \n",
    "     \n",
    "X = df[['SAT']]    \n",
    "Y = df['COLGPA']   \n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()    \n",
    "regr.fit(X, Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " -4.559680494246219\n",
      "Coefficients: \n",
      " [1.88850821]\n"
     ]
    }
   ],
   "source": [
    "print('Intercept: \\n', regr.intercept_) \n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  wages   R-squared:                       0.177\n",
      "Model:                            OLS   Adj. R-squared:                  0.176\n",
      "Method:                 Least Squares   F-statistic:                     188.3\n",
      "Date:                Tue, 04 Feb 2020   Prob (F-statistic):           5.85e-39\n",
      "Time:                        10:26:23   Log-Likelihood:                -3342.0\n",
      "No. Observations:                 879   AIC:                             6688.\n",
      "Df Residuals:                     877   BIC:                             6697.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.5597      1.777     -2.565      0.010      -8.048      -1.071\n",
      "education      1.8885      0.138     13.721      0.000       1.618       2.159\n",
      "==============================================================================\n",
      "Omnibus:                      332.295   Durbin-Watson:                   1.813\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1246.012\n",
      "Skew:                           1.797   Prob(JB):                    2.70e-271\n",
      "Kurtosis:                       7.595   Cond. No.                         63.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "R-Squared: \n",
      " 0.17674184783250557\n",
      "Adjusted R-squared: \n",
      " 0.17580312702045597\n",
      "Standard errors of coefficients: \n",
      " const        1.777347\n",
      "education    0.137631\n",
      "dtype: float64\n",
      "Standard error or regression: \n",
      " 10.850407260281331\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())\n",
    "print('R-Squared: \\n', results.rsquared)\n",
    "print('Adjusted R-squared: \\n', results.rsquared_adj)\n",
    "print('Standard errors of coefficients: \\n', results.bse)\n",
    "print('Standard error or regression: \\n', np.sqrt(results.scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summary.csv', 'w') as fh:\n",
    "    fh.write(results.summary().as_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
